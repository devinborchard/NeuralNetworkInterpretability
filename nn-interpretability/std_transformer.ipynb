{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","mount_file_id":"1MAI-FHTj2Gai0_P6UOz2Rp8Xc9vZiypK","authorship_tag":"ABX9TyNmIGpqPTxniJsqxP4qWWyN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"8796b8a515b54bf788c87d90114d5bc9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_793fec333c0841aa831565beb84d929f","IPY_MODEL_eae9cfae62b24b20b791df551ec1e116","IPY_MODEL_72f16ee45c324adca69e7ab1ebe13f24"],"layout":"IPY_MODEL_dc01778c04984dd2997f58471ffb15dc"}},"793fec333c0841aa831565beb84d929f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8081e0b024754a6ba84fae504f0e5362","placeholder":"​","style":"IPY_MODEL_81e284e4fc344440a0a4bc5373ae570c","value":"Sanity Checking DataLoader 0:   0%"}},"eae9cfae62b24b20b791df551ec1e116":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc4e4b5af3cc4e05b95ea0a8c519cac1","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8223610f820c4c79af6c6a510ea48a3b","value":0}},"72f16ee45c324adca69e7ab1ebe13f24":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_09b0ac4fe594447f8a56c29fc926156b","placeholder":"​","style":"IPY_MODEL_187577fc1d504fdf903f5ea709668384","value":" 0/2 [00:07&lt;?, ?it/s]"}},"dc01778c04984dd2997f58471ffb15dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"8081e0b024754a6ba84fae504f0e5362":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81e284e4fc344440a0a4bc5373ae570c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dc4e4b5af3cc4e05b95ea0a8c519cac1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8223610f820c4c79af6c6a510ea48a3b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"09b0ac4fe594447f8a56c29fc926156b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"187577fc1d504fdf903f5ea709668384":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cbe211fdae5d47fa8c11c6ac7eba4a2c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eeab561aa73342d3873d6a143ed47f55","IPY_MODEL_d77421b8f95245a39a44be94e0b73545","IPY_MODEL_7dc268738df5441e894dfb05dff1d9a6"],"layout":"IPY_MODEL_1e6b79dd90454a96adcb8ebb0fa5f084"}},"eeab561aa73342d3873d6a143ed47f55":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf39ac40f41d4583babd4d26492d73a1","placeholder":"​","style":"IPY_MODEL_65c2888eba6b4e908666ab0da25aa83b","value":"Validation: "}},"d77421b8f95245a39a44be94e0b73545":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_666d1a0f8e4445f4bb02b2245f1fa437","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ce61b25368314000b6700cab254b4221","value":1}},"7dc268738df5441e894dfb05dff1d9a6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7db1839d806d4bd5af53fa0fbc9b3768","placeholder":"​","style":"IPY_MODEL_4aa0e7173e244866b760e976aa0aaa08","value":" 20/? [01:37&lt;00:00,  4.88s/it]"}},"1e6b79dd90454a96adcb8ebb0fa5f084":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"cf39ac40f41d4583babd4d26492d73a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65c2888eba6b4e908666ab0da25aa83b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"666d1a0f8e4445f4bb02b2245f1fa437":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce61b25368314000b6700cab254b4221":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7db1839d806d4bd5af53fa0fbc9b3768":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4aa0e7173e244866b760e976aa0aaa08":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["def print_example(data, index, print_content=True, print_classification=True, print_rationales=True ):\n","    print(f'Retrieving Training Example [{index}].................\\n')\n","    item = data[index]\n","    classification = item['classification']\n","    evidences = item['evidences']\n","    content = item['content']\n","    if print_content: print(f'Review content:\\n{content}\\n')\n","    if print_classification: print('----------------------------',\n","                                   '\\n| Sentiment class:',\n","                                   classification,\n","                                   (\"- NEG\" if not classification else \"- POS\"),\n","                                   '|', '\\n----------------------------')\n","    if print_rationales:\n","        print('\\nHuman rationales / Supporting Evidence:')\n","        for evidence in evidences:\n","            print('     - ', evidence[0])\n","\n","def get_content(data, index):\n","    item = data[index]\n","    content = item['content']\n","    return content\n","\n","def get_classes(data, index):\n","    item = data[index]\n","    classification = item['classification']\n","    return torch.tensor(classification)\n","\n","def get_annotations(data, index):\n","    item = data[index]\n","    content = item['evidences']\n","    annotations = [evidence for evidence in content]\n","    return annotations\n"],"metadata":{"id":"aV9UQSh7cJSe","executionInfo":{"status":"ok","timestamp":1732756179510,"user_tz":300,"elapsed":104,"user":{"displayName":"Devin Borchard","userId":"08620990790600685895"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","from typing import List, Dict, Union\n","from transformers import BertTokenizerFast\n","\n","tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n","\n","# With it being easy to generate batches of tokenized texts, it's actually easier\n","# not to do the tokenization beforehand, and just store texts\n","# It's a little bit slow though, so if you found this to be bottleneck\n","# you'd want to pre-tokenize everything and then batch/pad as necessary\n","class SST2TransformerDataset(Dataset):\n","  def __init__(self,\n","               labels=None,\n","               texts=None):\n","\n","    self.y = torch.tensor(labels,dtype=torch.int64)\n","    self.texts = texts\n","\n","  def __len__(self):\n","    return self.y.shape[0]\n","\n","  def __getitem__(self, idx):\n","    rdict = {\n","      'y': self.y[idx],\n","      'text': self.texts[idx]\n","    }\n","    return rdict\n","\n","\n","def SST2_transformer_collate(batch:List[Dict[str, Union[torch.Tensor,str]]]):\n","  y_batch = torch.tensor([example['y'] for example in batch])\n","\n","  # We'll just reuse the tokenizer we created earlier, since it doesn't change\n","  tokenized_batch = tokenizer.batch_encode_plus([example['text'] for example in batch],\n","                                                return_tensors='pt',\n","                                                padding=True,\n","                                                max_length=512,\n","                                                truncation=True)\n","\n","  return {\n","      'y':y_batch,\n","      'input_ids':tokenized_batch['input_ids'],\n","      'attention_mask':tokenized_batch['attention_mask']\n","  }\n"],"metadata":{"id":"wHKInHxcg6_U","executionInfo":{"status":"ok","timestamp":1732756187172,"user_tz":300,"elapsed":7496,"user":{"displayName":"Devin Borchard","userId":"08620990790600685895"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9149af86-b21a-4e57-8c26-08e44121a845"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["from torch.utils.data import Dataset, DataLoader, TensorDataset\n","\n","train_data_path = 'drive/MyDrive/google_colab_data/train_data_loader.pt'\n","test_data_path = 'drive/MyDrive/google_colab_data/test_data_loader.pt'\n","val_data_path = 'drive/MyDrive/google_colab_data/val_data_loader.pt'\n","\n","def load_dataLoader(path):\n","  loaded_data = torch.load(path)\n","\n","  # Recreate the TensorDataset\n","  loaded_input = loaded_data['input']\n","  loaded_Y_star = loaded_data['Y_star']\n","  loaded_dataset = SST2TransformerDataset(loaded_Y_star, loaded_input)\n","\n","  # Recreate the DataLoader\n","  dataLoader = DataLoader(\n","      loaded_dataset,\n","      collate_fn = SST2_transformer_collate,\n","      batch_size=loaded_data['dataloader_params']['batch_size'],\n","      shuffle=loaded_data['dataloader_params']['shuffle'],  # Use shuffle from the saved data\n","      num_workers=loaded_data['dataloader_params']['num_workers']\n","  )\n","  return (dataLoader, len(loaded_input), loaded_input, loaded_Y_star)\n","\n","(train_dataloader, train_size, train_in, train_classes) = load_dataLoader(train_data_path)\n","(dev_dataloader, test_size, test_in, test_classes) = load_dataLoader(test_data_path)\n","(val_dataloader, val_data, val_in, val_classes) = load_dataLoader(val_data_path)"],"metadata":{"id":"oXx4Fqfdyneq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732756187394,"user_tz":300,"elapsed":223,"user":{"displayName":"Devin Borchard","userId":"08620990790600685895"}},"outputId":"c75b37af-5abc-46bf-b62b-e5423630f6cf"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-3-5a643227df58>:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  loaded_data = torch.load(path)\n"]}]},{"cell_type":"markdown","source":["# BERT Classifier"],"metadata":{"id":"QkD4crGTekou"}},{"cell_type":"code","source":["! pip install --quiet \"pytorch-lightning==1.9.4\"\n"],"metadata":{"id":"3Q6PYCDeesoX","executionInfo":{"status":"ok","timestamp":1732756190914,"user_tz":300,"elapsed":3521,"user":{"displayName":"Devin Borchard","userId":"08620990790600685895"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["from transformers import BertModel\n","# Like the tokenizer, we can just download one of these from Hugging Face\n","bert = BertModel.from_pretrained('bert-base-uncased')"],"metadata":{"id":"Eq_y3rHifXnl","executionInfo":{"status":"ok","timestamp":1732756208318,"user_tz":300,"elapsed":17406,"user":{"displayName":"Devin Borchard","userId":"08620990790600685895"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["import pytorch_lightning as pl\n","from torchmetrics.classification import BinaryAccuracy\n","from transformers import BertModel\n","import torch\n","\n","class BertClassifier(pl.LightningModule):\n","  def __init__(self,\n","               learning_rate:float,\n","               num_classes:int,\n","               freeze_bert:bool=False,\n","               **kwargs):\n","    super().__init__(**kwargs)\n","\n","    # Like with the LSTM, we'll define a central BERT we're gonna use\n","    # Again, this will download this from Hugging Face in the background\n","    self.bert = BertModel.from_pretrained('bert-base-uncased')\n","\n","    # If we want to speed up training, we can freeze the BERT module and train\n","    # just the output layer. This will hurt accuracy though.\n","    if freeze_bert:\n","      for param in self.bert.parameters():\n","        param.requires_grad = False\n","\n","    # Then the only other thing we need is an output layer, whose input size will\n","    # be the BERT's output size (768), which can can find as follows:\n","    self.output_layer = torch.nn.Linear(self.bert.config.hidden_size, num_classes)\n","\n","    self.learning_rate = learning_rate\n","    self.train_accuracy = BinaryAccuracy()\n","    self.val_accuracy = BinaryAccuracy()\n","    self.test_accuracy = BinaryAccuracy()\n","\n","\n","  def forward(self, y:torch.Tensor, input_ids:torch.Tensor,\n","              attention_mask:torch.Tensor):\n","    # And then the forward function is pretty simple--\n","    # way simpler than with the LSTM\n","    bert_result = self.bert(input_ids=input_ids,\n","                            attention_mask=attention_mask)\n","\n","    # Typically we just use the pooler output for classification\n","    # Which, again, is the hidden state output for the [CLS] token\n","    cls_output = bert_result['pooler_output']\n","\n","    py_logits = self.output_layer(cls_output)\n","    probs = torch.sigmoid(py_logits).view(-1)  # Convert logits to probabilities\n","\n","    py = (probs > 0.5).float()\n","    if(y is not None):\n","      loss = torch.nn.functional.binary_cross_entropy_with_logits(py_logits.view(-1), y.float())\n","    else:\n","      loss = None\n","    return {'py':py,\n","            'probs':probs,\n","            'loss':loss}\n","\n","  # Then do all the usual PyTorch Lightning functions\n","  def configure_optimizers(self):\n","    return [torch.optim.Adam(self.parameters(), lr=self.learning_rate)]\n","\n","  def training_step(self, batch, batch_idx):\n","    result = self.forward(**batch)\n","    loss = result['loss']\n","    self.log('train_loss', result['loss'])\n","    self.train_accuracy.update(result['py'], batch['y'])\n","    return loss\n","\n","  def training_epoch_end(self, outs):\n","    print(f' Epoch {self.current_epoch} training accuracy:', self.train_accuracy.compute())\n","    self.train_accuracy.reset()\n","\n","  def validation_step(self, batch, batch_idx):\n","    # with torch.enable_grad():  # Enable gradient calculation during validation step\n","    result = self.forward(**batch)\n","    self.val_accuracy.update(result['py'], batch['y'])\n","    return result['loss']\n","\n","  def validation_epoch_end(self, outs):\n","    print(f'Epoch {self.current_epoch} step {self.global_step} validation accuracy:', self.val_accuracy.compute())\n","    self.val_accuracy.reset()\n","\n","  def test_step(self, batch, batch_idx):\n","    result = self.forward(**batch)\n","    self.test_accuracy.update(result['py'], batch['y'])\n","    return result['loss']\n","\n","  def test_epoch_end(self, outs):\n","    print(f'Test accuracy:', self.test_accuracy.compute())\n","    self.test_accuracy.reset()"],"metadata":{"id":"Z1qVw-PxejrH","executionInfo":{"status":"ok","timestamp":1732756613952,"user_tz":300,"elapsed":105,"user":{"displayName":"Devin Borchard","userId":"08620990790600685895"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["classifier_model = BertClassifier(learning_rate=2e-5, #if we were fine-tuning the BERT, we'd want to use something like 2e-5\n","                            num_classes=1)\n","# classifier_model = classifier_model.to('cuda')\n","print('Model:')\n","print(classifier_model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SBl7QTjzftYf","executionInfo":{"status":"ok","timestamp":1732756616936,"user_tz":300,"elapsed":396,"user":{"displayName":"Devin Borchard","userId":"08620990790600685895"}},"outputId":"287a22c0-c504-440c-cf63-1785c1b8e9ee"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Model:\n","BertClassifier(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSdpaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (output_layer): Linear(in_features=768, out_features=1, bias=True)\n","  (train_accuracy): BinaryAccuracy()\n","  (val_accuracy): BinaryAccuracy()\n","  (test_accuracy): BinaryAccuracy()\n",")\n"]}]},{"cell_type":"code","source":["torch.random.manual_seed(10)\n","first_train_batch = next(iter(train_dataloader))\n","print('First training batch:')\n","print(first_train_batch)\n","\n","print('First training batch sizes:')\n","print({key:value.shape for key, value in first_train_batch.items()})\n","\n","# first_dev_batch = next(iter(dev_dataloader))\n","# print('First training batch:')\n","# print(first_dev_batch)\n","\n","# print('First training batch sizes:')\n","# print({key:value.shape for key, value in first_dev_batch.items()})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Avm2BjVjMU1","executionInfo":{"status":"ok","timestamp":1732756210982,"user_tz":300,"elapsed":3,"user":{"displayName":"Devin Borchard","userId":"08620990790600685895"}},"outputId":"79289c63-2ddc-45d8-f1b4-26ff780ec9c3"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["First training batch:\n","{'y': tensor([1, 1, 0, 0, 1, 1, 1, 1, 0, 0]), 'input_ids': tensor([[  101,  2096,  3898,  ..., 16344,  1029,   102],\n","        [  101, 18269,  1024,  ...,  2872,  1999,   102],\n","        [  101, 19962, 22599,  ...,  1055,  1037,   102],\n","        ...,\n","        [  101,  8383,  1006,  ..., 11721, 15378,   102],\n","        [  101,  2009,  2003,  ...,  2187,  2017,   102],\n","        [  101,  2045,  2001,  ...,  1010, 19031,   102]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        ...,\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 1, 1, 1]])}\n","First training batch sizes:\n","{'y': torch.Size([10]), 'input_ids': torch.Size([10, 512]), 'attention_mask': torch.Size([10, 512])}\n"]}]},{"cell_type":"code","source":["from pprint import pprint\n","with torch.no_grad():\n","  first_train_output = classifier_model(**first_train_batch)\n","\n","print('First training output:')\n","pprint(first_train_output)\n","\n","print('Output item shapes:')\n","pprint({key:value.shape for key, value in first_train_output.items()})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZvjSHGc9PmwN","executionInfo":{"status":"ok","timestamp":1732756222167,"user_tz":300,"elapsed":11090,"user":{"displayName":"Devin Borchard","userId":"08620990790600685895"}},"outputId":"43ede35a-da00-484e-bd2a-c1366168777e"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["First training output:\n","{'loss': tensor(0.6750),\n"," 'probs': tensor([0.5592, 0.5766, 0.5555, 0.5811, 0.5488, 0.5768, 0.5724, 0.5656, 0.5539,\n","        0.5733]),\n"," 'py': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])}\n","Output item shapes:\n","{'loss': torch.Size([]), 'probs': torch.Size([10]), 'py': torch.Size([10])}\n"]}]},{"cell_type":"code","source":["torch.cuda.is_available()\n","# torch.set_float32_matmul_precision('medium')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wZP_18HGJRVv","executionInfo":{"status":"ok","timestamp":1732756222167,"user_tz":300,"elapsed":10,"user":{"displayName":"Devin Borchard","userId":"08620990790600685895"}},"outputId":"a4e12ef8-f687-493d-d92a-f5e921d5bb52"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["# LOAD PARAMS"],"metadata":{"id":"pt-jY-SkMPJH"}},{"cell_type":"code","source":["import collections\n","import json\n","\n","def stringify_ordered_dict_with_tensors(ordered_dict):\n","    serializable_dict = {k: v.tolist() for k, v in ordered_dict.items()}  # Convert tensors to lists\n","    return json.dumps(serializable_dict)\n","\n","# Function to parse the string back to an OrderedDict of tensors\n","def parse_ordered_dict_with_tensors(stringified):\n","    deserialized_dict = json.loads(stringified)\n","    return collections.OrderedDict({k: torch.tensor(v) for k, v in deserialized_dict.items()})"],"metadata":{"id":"nQo3DchAr6wP","executionInfo":{"status":"ok","timestamp":1732756222168,"user_tz":300,"elapsed":11,"user":{"displayName":"Devin Borchard","userId":"08620990790600685895"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["params_path = 'drive/MyDrive/google_colab_data/params_std.txt'\n","data = ''\n","with open(params_path, 'r') as file:\n","  for line in file:\n","    data = data + line\n","# print(data)\n","parsed = parse_ordered_dict_with_tensors(data)\n","classifier_model.load_state_dict(parsed)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NiJi3E_DMIen","executionInfo":{"status":"ok","timestamp":1732760836306,"user_tz":300,"elapsed":101248,"user":{"displayName":"Devin Borchard","userId":"08620990790600685895"}},"outputId":"3b25e01f-3f3a-48a9-c4bc-4d2f57c8dbe6"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","source":["# TRAIN"],"metadata":{"id":"58nhU2P7MQ8K"}},{"cell_type":"code","source":["from pytorch_lightning import Trainer\n","from pytorch_lightning.callbacks.progress import TQDMProgressBar\n","\n","# And then training is easy with our old friend PyTorch Lightning\n","classifier_trainer = Trainer(\n","    accelerator=\"auto\",\n","    devices=1 if torch.cuda.is_available() else None,\n","    max_epochs=1,\n","    callbacks=[TQDMProgressBar(refresh_rate=20)],\n","    val_check_interval = 0.2,\n","    )\n","\n","# Note that this is the best accuracy we've seen on this dataset, by a pretty wide margin"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kiLfoX1ngxDb","executionInfo":{"status":"ok","timestamp":1732756731083,"user_tz":300,"elapsed":82,"user":{"displayName":"Devin Borchard","userId":"08620990790600685895"}},"outputId":"184aca9c-87dd-463e-edbd-513c70008328"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"]}]},{"cell_type":"code","source":["classifier_trainer.fit(model=classifier_model,\n","            train_dataloaders=train_dataloader,\n","            val_dataloaders=dev_dataloader)\n"],"metadata":{"id":"fGmMfwBxXYli","colab":{"base_uri":"https://localhost:8080/","height":364,"referenced_widgets":["8796b8a515b54bf788c87d90114d5bc9","793fec333c0841aa831565beb84d929f","eae9cfae62b24b20b791df551ec1e116","72f16ee45c324adca69e7ab1ebe13f24","dc01778c04984dd2997f58471ffb15dc","8081e0b024754a6ba84fae504f0e5362","81e284e4fc344440a0a4bc5373ae570c","dc4e4b5af3cc4e05b95ea0a8c519cac1","8223610f820c4c79af6c6a510ea48a3b","09b0ac4fe594447f8a56c29fc926156b","187577fc1d504fdf903f5ea709668384"]},"executionInfo":{"status":"ok","timestamp":1732760878842,"user_tz":300,"elapsed":4217,"user":{"displayName":"Devin Borchard","userId":"08620990790600685895"}},"outputId":"9d4c3e70-6ca4-46f5-8533-69f1c21e4f27"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:613: UserWarning: Checkpoint directory /content/lightning_logs/version_5/checkpoints exists and is not empty.\n","  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n","INFO:pytorch_lightning.callbacks.model_summary:\n","  | Name           | Type           | Params\n","--------------------------------------------------\n","0 | bert           | BertModel      | 109 M \n","1 | output_layer   | Linear         | 769   \n","2 | train_accuracy | BinaryAccuracy | 0     \n","3 | val_accuracy   | BinaryAccuracy | 0     \n","4 | test_accuracy  | BinaryAccuracy | 0     \n","--------------------------------------------------\n","109 M     Trainable params\n","0         Non-trainable params\n","109 M     Total params\n","437.932   Total estimated model params size (MB)\n"]},{"output_type":"display_data","data":{"text/plain":["Sanity Checking: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8796b8a515b54bf788c87d90114d5bc9"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n","  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"]}]},{"cell_type":"code","source":["val_results = classifier_trainer.validate(model=classifier_model, dataloaders=val_dataloader)\n","\n","# Print the validation results\n","print(\"Validation Results:\", val_results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":84,"referenced_widgets":["cbe211fdae5d47fa8c11c6ac7eba4a2c","eeab561aa73342d3873d6a143ed47f55","d77421b8f95245a39a44be94e0b73545","7dc268738df5441e894dfb05dff1d9a6","1e6b79dd90454a96adcb8ebb0fa5f084","cf39ac40f41d4583babd4d26492d73a1","65c2888eba6b4e908666ab0da25aa83b","666d1a0f8e4445f4bb02b2245f1fa437","ce61b25368314000b6700cab254b4221","7db1839d806d4bd5af53fa0fbc9b3768","4aa0e7173e244866b760e976aa0aaa08"]},"id":"DrdC950nqLug","executionInfo":{"status":"ok","timestamp":1732760979891,"user_tz":300,"elapsed":97654,"user":{"displayName":"Devin Borchard","userId":"08620990790600685895"}},"outputId":"72e01322-46f0-4f85-e8d7-242bd05c7507"},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbe211fdae5d47fa8c11c6ac7eba4a2c"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1 step 160 validation accuracy: tensor(0.8550)\n","Validation Results: [{}]\n"]}]},{"cell_type":"markdown","source":["# SAVE PARAMS"],"metadata":{"id":"G0iFZJJQNc8p"}},{"cell_type":"code","source":["params_path = 'drive/MyDrive/google_colab_data/params_std.txt'\n","!mkdir -p params_path\n","with open(params_path, 'w') as f:\n","  f.write(stringify_ordered_dict_with_tensors(classifier_model.state_dict()))"],"metadata":{"id":"bc1n5gd4Kl2Q"},"execution_count":null,"outputs":[]}]}